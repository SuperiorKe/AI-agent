version: '3.8'

services:
  ai-agent:
    build: .
    container_name: ai-content-assistant
    ports:
      - "8501:8501"
    environment:
      # API Keys - Set these in your .env file or override here
      - CHATBOT_API_KEY=${CHATBOT_API_KEY}
      - TAVILY_API_KEY=${TAVILY_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - GOOGLE_API_KEY=${GOOGLE_API_KEY}
      # Model configuration
      - CHATBOT_MODEL=${CHATBOT_MODEL:-openai:gpt-4}
      # Environment
      - ENV=${ENV:-production}
      # LinkedIn API (optional)
      - LINKEDIN_CLIENT_ID=${LINKEDIN_CLIENT_ID}
      - LINKEDIN_CLIENT_SECRET=${LINKEDIN_CLIENT_SECRET}
    volumes:
      # Mount for persistent data and logs
      - ./data:/app/data
      - ./logs:/app/logs
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8501/_stcore/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ai-agent-network

  # Optional: Add a Redis service for caching (uncomment if needed)
  # redis:
  #   image: redis:7-alpine
  #   container_name: ai-agent-redis
  #   ports:
  #     - "6379:6379"
  #   volumes:
  #     - redis_data:/data
  #   restart: unless-stopped
  #   networks:
  #     - ai-agent-network

networks:
  ai-agent-network:
    driver: bridge

# Optional: Redis volume (uncomment if using Redis)
# volumes:
#   redis_data: 